ChatGPT é brilhante, mas às vezes damos mais crédito do que merece. Podemos cometer grandes erros se não verificarmos o resultado de uma IA.

Como regra geral, tente lembrar - se do seguinte princípio. Um especialista em seu campo trabalha com IA e razões dentro da caixa de conversação IA em vez de copiar e colar todas as respostas e confiar sem pensar. Na verdade, OpenAI afirma claramente na tela: "Chat GPT pode cometer erros. Verifique informações importantes."

Você pode obter dois tipos de comportamento indesejado de ferramentas GenAI, alucinações e inconsistências. 

As alucinações são observadas quando a IA fornece saída falsa para gerar qualquer produção. Agora que você entende como a GenAI funciona, você percebe que os modelos geralmente predizem a próxima palavra em uma sequência usando contexto para melhorar a precisão. Apesar do poder e sofisticação desses modelos, suas previsões podem ocasionalmente ser incorretas. Outra razão pela qual as alucinações poderiam ocorrer é que a IA poderia ser treinada em dados factualmente incorretos para começar. Se treinado com dados falsos, o modelo provavelmente produzirá saídas incorretas, certo? Uma tática legítima para lidar com alucinações é dar uma instrução que diz: "forneça uma resposta apenas se você sabe a resposta". Em alguns casos, este tipo de engenharia rápida poderia ser útil. 

Por outro lado, a inconsistência ocorre quando um modelo fornece respostas muito diferentes para a mesma questão. Especialmente quando o ChatGPT saiu pela primeira vez, parecia que a IA era mais inteligente em sessões específicas e mais burra em outras. Isso é devido a variações no hardware usado para executar o modelo ou outros fatores incontroláveis, principalmente quando o modelo é hospedado externamente.
Uma maneira não comprovada de reduzir a inconsistência é instruindo a IA a tomar seu tempo. Com sorte, se você fizer isso, ele não vai se apressar para produzir uma resposta, e o sistema poderia alocar mais recursos de hardware para cada prompt. Em qualquer caso, detectar alucinações e inconsistências e encontrar formas de lidar com elas será um dos principais tópicos da pesquisa de IA nos próximos anos, e certamente se tornará um mercado que vale bilhões.